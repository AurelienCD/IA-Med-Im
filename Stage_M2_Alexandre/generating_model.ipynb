{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:28:07.824100Z",
     "start_time": "2024-06-10T13:28:05.754285Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from data.CustomImageDataset import GenerationImageDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.v2 import Grayscale, ToDtype, Lambda, CenterCrop, Resize, ToPILImage\n",
    "from einops import rearrange\n",
    "from utils.visualization import plot_graph\n",
    "torch.cuda.empty_cache()"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fd57c525d903c69e",
   "metadata": {},
   "source": [
    "## Chargement des donn√©es"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:28:07.855607Z",
     "start_time": "2024-06-10T13:28:07.825100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# define image transformations (e.g. using torchvision)\n",
    "transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(\n",
    "    root=\"./data/datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    \n",
    ")\n",
    "channels, image_size, _ = dataset[0][0].shape\n",
    "batch_size = 128\n",
    "\n",
    "# create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "819d3fa129529324",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f4e0fa722f2437b1",
   "metadata": {},
   "source": [
    "## Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0561f85d533143f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:28:07.982039Z",
     "start_time": "2024-06-10T13:28:07.857608Z"
    }
   },
   "source": [
    "from models.TemporalUNet import TemporalUNet\n",
    "from models.DDPM import DDPM\n",
    "\n",
    "unet = TemporalUNet(in_channels=1, out_channels=1, channels_mult=(1, 2, 4))\n",
    "\n",
    "diffusion_model = DDPM(denoiser=unet, timestep=300, schedule_type='linear')"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8a6d48862c864b20",
   "metadata": {},
   "source": [
    "### Check model settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277eaadf08f77a8",
   "metadata": {},
   "source": [
    "### Sur-apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "id": "56ff2d453b3223c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:28:10.883259Z",
     "start_time": "2024-06-10T13:28:07.983039Z"
    }
   },
   "source": [
    "from torch.optim import Adam\n",
    "from utils.trainer.DiffusionModelTrainer import DiffusionModelTrainer\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer  = Adam(params=unet.parameters(), lr=learning_rate)\n",
    "\n",
    "#short_train_dataset = torch.utils.data.Subset(train_dataset, indices=torch.arange(0, 4))\n",
    "\n",
    "trainer = DiffusionModelTrainer(model=diffusion_model, train_dataset=dataset, test_dataset=dataset, loss_fn=diffusion_model.compute_loss, optimizer=optimizer, batch_size=128)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "130687ff9b119218",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T13:30:24.818053Z",
     "start_time": "2024-06-10T13:28:10.884264Z"
    }
   },
   "source": [
    "losses = trainer.train(num_epochs=6)\n",
    "#torch.save(unet.state_dict(), 'weights/diffusion_unet_overfit_b8_t300_cosine_lr25_c1.pt')"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:04.211599Z",
     "start_time": "2024-06-10T12:12:04.203294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule as proposed in https://arxiv.org/abs/2102.09672\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)"
   ],
   "id": "bff8cf52fd7cc2ac",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:04.555403Z",
     "start_time": "2024-06-10T12:12:04.545893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "timesteps = 300\n",
    "\n",
    "# define beta schedule\n",
    "betas = linear_beta_schedule(timesteps=timesteps)\n",
    "\n",
    "# define alphas \n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "\n",
    "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = a.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n"
   ],
   "id": "8608a41b6429fafd",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:04.978880Z",
     "start_time": "2024-06-10T12:12:04.960618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def p_sample(model, x, t, t_index):\n",
    "    betas_t = extract(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
    "    \n",
    "    # Equation 11 in the paper\n",
    "    # Use our model (noise predictor) to predict the mean\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "\n",
    "    if t_index == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
    "        noise = torch.randn_like(x)\n",
    "        # Algorithm 2 line 4:\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise \n",
    "\n",
    "# Algorithm 2 (including returning all images)\n",
    "@torch.no_grad()\n",
    "def p_sample_loop(model, shape):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    b = shape[0]\n",
    "    # start from pure noise (for each example in the batch)\n",
    "    img = torch.randn(shape, device=device)\n",
    "    imgs = []\n",
    "\n",
    "    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n",
    "        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
    "        imgs.append(img.cpu().numpy())\n",
    "    return imgs\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, image_size, batch_size=16, channels=3):\n",
    "    return p_sample_loop(model, shape=(batch_size, channels, image_size, image_size))"
   ],
   "id": "ceb795245978cfb3",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:05.529832Z",
     "start_time": "2024-06-10T12:12:05.526832Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "c0b715193be4295a",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:05.906113Z",
     "start_time": "2024-06-10T12:12:05.895109Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "80c02f45c904957",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:18.046044Z",
     "start_time": "2024-06-10T12:12:13.618854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = sample(unet, image_size=image_size, batch_size=128, channels=1)\n",
    "plt.imshow(samples[-1][6].reshape(image_size, image_size, channels), cmap='gray')"
   ],
   "id": "fa3ffead6269d484",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:21.227266Z",
     "start_time": "2024-06-10T12:12:21.207380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples[-1][0].min()"
   ],
   "id": "f6b91cbfc4d75c59",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "3dc9959b254cface",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "2ebf7ec6d38c6fda",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "62817092c6bb78fb",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "6a8dcb4f8084f5e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.visualization import plot_graph\n",
    "plot_graph(x = np.arange(len(losses['training_loss'])), \n",
    "           y = losses['training_loss'],\n",
    "           xlabel='epoch', \n",
    "           ylabel=r'$loss$', \n",
    "           title='MSE Loss evolution on training set')"
   ],
   "id": "6b3af81e6313505e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unet.load_state_dict(torch.load('weights/diffusion_unet_overfit_b8_t300_cosine_lr25_c1.pt', map_location=torch.device('cuda:0')))"
   ],
   "id": "f629b07039d14488",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1b82d2f89dd52a1a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Illustration du processus avant de diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab84e8-f229-4101-a05a-a083b5225439",
   "metadata": {},
   "source": [
    "### Evaluating variable shape"
   ]
  },
  {
   "cell_type": "code",
   "id": "1a1bafc2b1ff342d",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "num_images = 10\n",
    "\n",
    "x0 = dataset[0].to('cuda')\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=(num_images+1), figsize=((num_images+1)*2, 2))\n",
    "plt.axis('off')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title(f't: {0}')\n",
    "axs[0].imshow(reverse_transformation(x0.cpu()), cmap='gray')\n",
    "\n",
    "x0 = rearrange(x0, 'c h w -> 1 c h w')\n",
    "t = int(diffusion_model.timestep /num_images)\n",
    "x_noisy = diffusion_model.forward_sampling(x0, torch.tensor([t], dtype=torch.int64, device=x0.device))\n",
    "\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title(f't: {t}')\n",
    "axs[1].imshow(reverse_transformation(rearrange(x_noisy, '1 c h w -> c h w').cpu()), cmap='gray')\n",
    "for i in range(num_images - 2):\n",
    "    axs[i+2].axis('off')\n",
    "    t = int(diffusion_model.timestep / (num_images) * (i+2))\n",
    "    axs[i+2].set_title(f't: {t}')\n",
    "    x_noisy = diffusion_model.forward_sampling(x0, torch.tensor([t], dtype=torch.int64, device=x0.device))\n",
    "    axs[i+2].imshow(reverse_transformation(rearrange(x_noisy, '1 c h w -> c h w').cpu()), cmap='gray')\n",
    "    \n",
    "    axs[-1].axis('off')\n",
    "    t = diffusion_model.timestep - 1\n",
    "    axs[-1].set_title(f't: {t}')\n",
    "    x_noisy = diffusion_model.forward_sampling(x0, torch.tensor([t], dtype=torch.int64, device=x0.device))\n",
    "    axs[-1].imshow(reverse_transformation(rearrange(x_noisy, '1 c h w -> c h w').cpu()), cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a5a888b64c0fae86",
   "metadata": {},
   "source": [
    "## Processus arri√®re de diffusion"
   ]
  },
  {
   "cell_type": "code",
   "id": "77dbcced8a4bf280",
   "metadata": {},
   "source": [
    "x_rec = diffusion_model.reverse_sampling(x_noisy)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def normalize(x):\n",
    "    "
   ],
   "id": "5af8251f60145b19",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_rec[-1].max()"
   ],
   "id": "1c8b7db74aa76680",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d78dd1ae-fff9-4353-b55a-e507342a3520",
   "metadata": {},
   "source": [
    "num_images = 5\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=num_images+1, figsize=((num_images+1)*2, 2))\n",
    "plt.axis('off')\n",
    "for i in range(num_images):\n",
    "    t = int(diffusion_model.timestep * i / num_images)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f't: {t}')\n",
    "    axs[i].imshow(rearrange(x_rec[t], '1 c h w -> h w c').cpu(), cmap='gray')\n",
    "\n",
    "axs[-1].axis('off')\n",
    "axs[-1].set_title(f't: {diffusion_model.timestep-1}')\n",
    "axs[-1].imshow(rearrange(x_rec[-1], '1 c h w -> h w c').cpu(), cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "84b967452b888cf4",
   "metadata": {},
   "source": [
    "## Affiche les infos sur le mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee70566f-90f2-459b-9342-4290ff8d46b7",
   "metadata": {},
   "source": [
    "x_rec[299]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5387068026b25cef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "train_dataset[0].shape"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ec5b41a39848f91f",
   "metadata": {},
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary_kwargs = dict(col_names=['input_size', 'output_size', 'kernel_size', 'num_params', 'mult_adds'], depth=3, verbose=0)\n",
    "\n",
    "summary(unet, input_data=(torch.ones(16, 1, 256, 256), torch.ones(16, 1)), batch_dim=0, **summary_kwargs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7c762ad0c0f3f841",
   "metadata": {},
   "source": [
    "Rappel, une RTX 4080 √† une puissance de 48.74 TFlops (FP32) Soit $48.74 \\times 10^{12}$ op√©rations par secondes en float32.\n",
    "Avec une profondeur de 5 blocs:\n",
    "Ici, nous lisons que le mod√®le effectue $82.15 \\times 10^9$ op√©rations pour une image avec des couches r√©siduelles. Nous avons aussi 114 millions de param√®tres au total.\n",
    "En utilisant rempla√ßant les couches r√©siduelles par des ResidualBottleneck, nous obtenons $20.26 \\times 10^9$ op√©rations et 33 millions de param√®tres pour le mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "id": "1a835e78f1d76e5c",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5f1ad689-3eef-479a-bcd0-f3c48a7ddccb",
   "metadata": {},
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e5ad7285777f626d",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "84f857ce393591c7",
   "metadata": {},
   "source": [
    "torch.tensor([1, *a[:-1]])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "563d35934e484806",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bb8aef255dc58cae",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b6fc57c23850758c",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
