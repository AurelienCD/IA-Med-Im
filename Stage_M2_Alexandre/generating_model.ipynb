{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:28:07.824100Z",
     "start_time": "2024-06-10T13:28:05.754285Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from data.CustomImageDataset import GenerationImageDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.v2 import Grayscale, ToDtype, Lambda, CenterCrop, Resize, ToPILImage\n",
    "from einops import rearrange\n",
    "from utils.visualization import plot_graph\n",
    "torch.cuda.empty_cache()"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fd57c525d903c69e",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:28:07.855607Z",
     "start_time": "2024-06-10T13:28:07.825100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# define image transformations (e.g. using torchvision)\n",
    "transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(\n",
    "    root=\"./data/datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    \n",
    ")\n",
    "channels, image_size, _ = dataset[0][0].shape\n",
    "batch_size = 128\n",
    "\n",
    "# create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "819d3fa129529324",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f4e0fa722f2437b1",
   "metadata": {},
   "source": [
    "## Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0561f85d533143f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:28:07.982039Z",
     "start_time": "2024-06-10T13:28:07.857608Z"
    }
   },
   "source": [
    "from models.TemporalUNet import TemporalUNet\n",
    "from models.DDPM import DDPM\n",
    "\n",
    "unet = TemporalUNet(in_channels=1, out_channels=1, channels_mult=(1, 2, 4))\n",
    "\n",
    "diffusion_model = DDPM(denoiser=unet, timestep=300, schedule_type='linear')"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8a6d48862c864b20",
   "metadata": {},
   "source": [
    "### Check model settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277eaadf08f77a8",
   "metadata": {},
   "source": [
    "### Sur-apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "id": "56ff2d453b3223c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:28:10.883259Z",
     "start_time": "2024-06-10T13:28:07.983039Z"
    }
   },
   "source": [
    "from torch.optim import Adam\n",
    "from utils.trainer.DiffusionModelTrainer import DiffusionModelTrainer\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer  = Adam(params=unet.parameters(), lr=learning_rate)\n",
    "\n",
    "#short_train_dataset = torch.utils.data.Subset(train_dataset, indices=torch.arange(0, 4))\n",
    "\n",
    "trainer = DiffusionModelTrainer(model=diffusion_model, train_dataset=dataset, test_dataset=dataset, loss_fn=diffusion_model.compute_loss, optimizer=optimizer, batch_size=128)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "130687ff9b119218",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T13:30:24.818053Z",
     "start_time": "2024-06-10T13:28:10.884264Z"
    }
   },
   "source": [
    "losses = trainer.train(num_epochs=6)\n",
    "#torch.save(unet.state_dict(), 'weights/diffusion_unet_overfit_b8_t300_cosine_lr25_c1.pt')"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:04.211599Z",
     "start_time": "2024-06-10T12:12:04.203294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule as proposed in https://arxiv.org/abs/2102.09672\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)"
   ],
   "id": "bff8cf52fd7cc2ac",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:04.555403Z",
     "start_time": "2024-06-10T12:12:04.545893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "timesteps = 300\n",
    "\n",
    "# define beta schedule\n",
    "betas = linear_beta_schedule(timesteps=timesteps)\n",
    "\n",
    "# define alphas \n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "\n",
    "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = a.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n"
   ],
   "id": "8608a41b6429fafd",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:04.978880Z",
     "start_time": "2024-06-10T12:12:04.960618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def p_sample(model, x, t, t_index):\n",
    "    betas_t = extract(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
    "    \n",
    "    # Equation 11 in the paper\n",
    "    # Use our model (noise predictor) to predict the mean\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "\n",
    "    if t_index == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
    "        noise = torch.randn_like(x)\n",
    "        # Algorithm 2 line 4:\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise \n",
    "\n",
    "# Algorithm 2 (including returning all images)\n",
    "@torch.no_grad()\n",
    "def p_sample_loop(model, shape):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    b = shape[0]\n",
    "    # start from pure noise (for each example in the batch)\n",
    "    img = torch.randn(shape, device=device)\n",
    "    imgs = []\n",
    "\n",
    "    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n",
    "        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
    "        imgs.append(img.cpu().numpy())\n",
    "    return imgs\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, image_size, batch_size=16, channels=3):\n",
    "    return p_sample_loop(model, shape=(batch_size, channels, image_size, image_size))"
   ],
   "id": "ceb795245978cfb3",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:05.529832Z",
     "start_time": "2024-06-10T12:12:05.526832Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "c0b715193be4295a",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:05.906113Z",
     "start_time": "2024-06-10T12:12:05.895109Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "80c02f45c904957",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:18.046044Z",
     "start_time": "2024-06-10T12:12:13.618854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = sample(unet, image_size=image_size, batch_size=128, channels=1)\n",
    "plt.imshow(samples[-1][6].reshape(image_size, image_size, channels), cmap='gray')"
   ],
   "id": "fa3ffead6269d484",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:12:21.227266Z",
     "start_time": "2024-06-10T12:12:21.207380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples[-1][0].min()"
   ],
   "id": "f6b91cbfc4d75c59",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "3dc9959b254cface",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "2ebf7ec6d38c6fda",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "62817092c6bb78fb",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "6a8dcb4f8084f5e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.visualization import plot_graph\n",
    "plot_graph(x = np.arange(len(losses['training_loss'])), \n",
    "           y = losses['training_loss'],\n",
    "           xlabel='epoch', \n",
    "           ylabel=r'$loss$', \n",
    "           title='MSE Loss evolution on training set')"
   ],
   "id": "6b3af81e6313505e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unet.load_state_dict(torch.load('weights/diffusion_unet_overfit_b8_t300_cosine_lr25_c1.pt', map_location=torch.device('cuda:0')))"
   ],
   "id": "f629b07039d14488",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1b82d2f89dd52a1a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Illustration du processus avant de diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab84e8-f229-4101-a05a-a083b5225439",
   "metadata": {},
   "source": [
    "### Evaluating variable shape"
   ]
  },
  {
   "cell_type": "code",
   "id": "1a1bafc2b1ff342d",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "num_images = 10\n",
    "\n",
    "x0 = dataset[0].to('cuda')\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=(num_images+1), figsize=((num_images+1)*2, 2))\n",
    "plt.axis('off')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title(f't: {0}')\n",
    "axs[0].imshow(reverse_transformation(x0.cpu()), cmap='gray')\n",
    "\n",
    "x0 = rearrange(x0, 'c h w -> 1 c h w')\n",
    "t = int(diffusion_model.timestep /num_images)\n",
    "x_noisy = diffusion_model.forward_sampling(x0, torch.tensor([t], dtype=torch.int64, device=x0.device))\n",
    "\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title(f't: {t}')\n",
    "axs[1].imshow(reverse_transformation(rearrange(x_noisy, '1 c h w -> c h w').cpu()), cmap='gray')\n",
    "for i in range(num_images - 2):\n",
    "    axs[i+2].axis('off')\n",
    "    t = int(diffusion_model.timestep / (num_images) * (i+2))\n",
    "    axs[i+2].set_title(f't: {t}')\n",
    "    x_noisy = diffusion_model.forward_sampling(x0, torch.tensor([t], dtype=torch.int64, device=x0.device))\n",
    "    axs[i+2].imshow(reverse_transformation(rearrange(x_noisy, '1 c h w -> c h w').cpu()), cmap='gray')\n",
    "    \n",
    "    axs[-1].axis('off')\n",
    "    t = diffusion_model.timestep - 1\n",
    "    axs[-1].set_title(f't: {t}')\n",
    "    x_noisy = diffusion_model.forward_sampling(x0, torch.tensor([t], dtype=torch.int64, device=x0.device))\n",
    "    axs[-1].imshow(reverse_transformation(rearrange(x_noisy, '1 c h w -> c h w').cpu()), cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a5a888b64c0fae86",
   "metadata": {},
   "source": [
    "## Processus arrière de diffusion"
   ]
  },
  {
   "cell_type": "code",
   "id": "77dbcced8a4bf280",
   "metadata": {},
   "source": [
    "x_rec = diffusion_model.reverse_sampling(x_noisy)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def normalize(x):\n",
    "    "
   ],
   "id": "5af8251f60145b19",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_rec[-1].max()"
   ],
   "id": "1c8b7db74aa76680",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d78dd1ae-fff9-4353-b55a-e507342a3520",
   "metadata": {},
   "source": [
    "num_images = 5\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=num_images+1, figsize=((num_images+1)*2, 2))\n",
    "plt.axis('off')\n",
    "for i in range(num_images):\n",
    "    t = int(diffusion_model.timestep * i / num_images)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(f't: {t}')\n",
    "    axs[i].imshow(rearrange(x_rec[t], '1 c h w -> h w c').cpu(), cmap='gray')\n",
    "\n",
    "axs[-1].axis('off')\n",
    "axs[-1].set_title(f't: {diffusion_model.timestep-1}')\n",
    "axs[-1].imshow(rearrange(x_rec[-1], '1 c h w -> h w c').cpu(), cmap='gray')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "84b967452b888cf4",
   "metadata": {},
   "source": [
    "## Affiche les infos sur le modèles"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee70566f-90f2-459b-9342-4290ff8d46b7",
   "metadata": {},
   "source": [
    "x_rec[299]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5387068026b25cef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "train_dataset[0].shape"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ec5b41a39848f91f",
   "metadata": {},
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary_kwargs = dict(col_names=['input_size', 'output_size', 'kernel_size', 'num_params', 'mult_adds'], depth=3, verbose=0)\n",
    "\n",
    "summary(unet, input_data=(torch.ones(16, 1, 256, 256), torch.ones(16, 1)), batch_dim=0, **summary_kwargs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7c762ad0c0f3f841",
   "metadata": {},
   "source": [
    "Rappel, une RTX 4080 à une puissance de 48.74 TFlops (FP32) Soit $48.74 \\times 10^{12}$ opérations par secondes en float32.\n",
    "Avec une profondeur de 5 blocs:\n",
    "Ici, nous lisons que le modèle effectue $82.15 \\times 10^9$ opérations pour une image avec des couches résiduelles. Nous avons aussi 114 millions de paramètres au total.\n",
    "En utilisant remplaçant les couches résiduelles par des ResidualBottleneck, nous obtenons $20.26 \\times 10^9$ opérations et 33 millions de paramètres pour le modèle."
   ]
  },
  {
   "cell_type": "code",
   "id": "1a835e78f1d76e5c",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5f1ad689-3eef-479a-bcd0-f3c48a7ddccb",
   "metadata": {},
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e5ad7285777f626d",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "84f857ce393591c7",
   "metadata": {},
   "source": [
    "torch.tensor([1, *a[:-1]])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "563d35934e484806",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bb8aef255dc58cae",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b6fc57c23850758c",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
